import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime, timedelta
import pytz
from openai import OpenAI
from supabase import create_client, Client
from dotenv import load_dotenv
import os


if "GITHUB_ACTIONS" not in os.environ:
    load_dotenv()

# get env from .env file
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
X_API_KEY = os.getenv("X_API_KEY")
OPEN_AI_KEY = os.getenv("OPEN_AI_KEY")
HEADER_TOKEN = os.getenv("HEADER_TOKEN")



# init supabase client
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def get_source_link(article_url):
    try:
        response = requests.get(article_url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        source_link_tag = soup.find('div', class_="rich_text_content mb-4").find('a', string='(æ¥æºé“¾æ¥)')
        if source_link_tag:
            return source_link_tag['href']
    except requests.RequestException as e:
        print("Failed to retrieve source link:", e)
    except AttributeError:
        print("Source link not found in the expected section.")
    return None

def get_formatted_news(api_url, headers, params):
    response = requests.post(api_url, headers=headers, json=params)
    if response.status_code == 200 and response.json().get('result') == 1:
        article = response.json()['data']['list'][0]
        if article:
            title, content, article_url, article_id = article['title'], article['content'], article['url'], article['id']
            return title, content, article_url, article_id
    return None, None, None, None

def format_content(title, content, prompt):
    news_content = f"{title} {content}"
    client = OpenAI(base_url="https://api.gptsapi.net/v1", api_key=OPEN_AI_KEY)
    response = client.chat.completions.create(model="gpt-4-turbo", messages=[{"role": "system", "content": prompt}, {"role": "user", "content": news_content}])
    if response.choices:
        formatted_news = "ğŸ’¡èµ„è®¯\n" + response.choices[0].message.content[:240]
        return formatted_news
    return "ğŸ’¡èµ„è®¯\nContent formatting failed."

def schedule_tweet(tweet_content):
    headers = {"X-API-KEY": f"Bearer {X_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "content": tweet_content,
        "schedule-date": (datetime.now(pytz.timezone('Asia/Shanghai')) + timedelta(seconds=30)).isoformat()
    }
    response = requests.post("https://api.typefully.com/v1/drafts/", json=payload, headers=headers)
    print(response.json())
    return "æ¨æ–‡å·²æˆåŠŸå‘å¸ƒï¼" if response.status_code == 200 else "æ¨æ–‡å‘å¸ƒå¤±è´¥ã€‚"

def is_article_id_exists(article_id):
    data = supabase.table("last_article").select("article_id").eq("article_id", article_id).execute()
    return len(data.data) > 0

def update_last_article_id(article_id):
    supabase.table("last_article").insert({"article_id": article_id}).execute()


def main():
    """
    Fetches news articles from an API, processes the content, and schedules a tweet.

    This function performs the following steps:
    1. Fetches news articles from the specified API endpoint.
    2. Checks if the article already exists in the database.
    3. If the article is new, formats the content and generates a tweet.
    4. Schedules the tweet for posting.
    5. Updates the last article ID in the database.

    Returns:
        None

    Raises:
        None
    """
    api_url = "https://www.chaincatcher.com/OpenApi/FetchListByType"
    headers = {"token": HEADER_TOKEN}
    params = {"type": 2, "newsFlashType": 1, "page": 1, "limit": 1}
    prompt = "è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼šè¾“å…¥åŸå§‹æ–‡æœ¬ã€‚é¦–å…ˆï¼Œä»æ–‡æœ¬ä¸­åˆ é™¤ä»»ä½•æåˆ°'ChainCatcheræ¶ˆæ¯'çš„éƒ¨åˆ†ã€‚ç„¶åï¼Œä¾æ®æ ‡é¢˜å†…å®¹å’Œæ­£æ–‡è¡¥å……ä¿¡æ¯ï¼Œå°†æ–‡æœ¬å†…å®¹å‹ç¼©æˆä¸è¶…è¿‡70å­—çš„æ‘˜è¦ï¼Œå¹¶ä¿æŒå†…å®¹ç”¨è¯­æ­£å¼ã€æ–°é—»æ ¼è°ƒï¼ŒåŒæ—¶ä¸­ç«‹å’Œå®¢è§‚ã€‚åœ¨å¤„ç†æ—¶ï¼Œè¯·ç¡®ä¿å°†æ‰€æœ‰ä¸åŠ å¯†è´§å¸é¢†åŸŸç›¸å…³çš„å…³é”®è¯å¦‚'æ¯”ç‰¹å¸'å’Œ'ETF'æ ‡è®°ä¸º#æ¯”ç‰¹å¸ã€#æ¯”ç‰¹å¸ã€#ETFã€#BTCã€#ETHã€#SECã€#FTXã€#SBFã€#çˆ†ä»“ã€#ç°åº¦ã€#å¸å®‰ã€#Coinbaseã€#GaryGenslerã€#OKXã€#Solanaã€#ä»¥å¤ªåŠã€#RWAã€#AIã€#Tetherã€#èµµé•¿é¹ã€#CZã€#åŒºå—é“¾ã€#åŠ å¯†è¡Œä¸šã€#è¨å°”ç“¦å¤šã€#ç¾è”å‚¨ã€#å…ƒå®‡å®™ã€#PEOPLEã€#PEPEã€#èèµ„ã€#SEIã€#Cosmosã€#åŠ å¯†èµ„äº§ã€#CPIã€#ä½•ä¸€ã€#DEXã€#CEXã€#SOLã€#OKBã€#BNBã€#é»‘å®¢æ”»å‡»ã€#memeã€#é²å¨å°”ã€#Runesã€#ç¬¦æ–‡ã€#é“­æ–‡ã€#Ordinalsã€#ORDIã€#Web3ã€#æ…¢é›¾ã€#Layer2ã€#å­™å®‡æ™¨ã€#USDTã€#USDCã€#TONã€#æ¸¯è‚¡ã€#é©¬æ–¯å…‹ã€#ç¨³å®šå¸ç­‰ï¼Œå¹¶åœ¨æ¯ä¸ªæ ‡ç­¾å‰åŠ ä¸Šç©ºæ ¼ï¼Œä½¿è¿™äº›æ ‡ç­¾åˆç†åœ°èå…¥åˆ°å¥å­ä¸­ï¼Œä¿æŒä¿¡æ¯æµç•…ä¸”æ˜“äºç†è§£"

    try:
        title, content, article_url, article_id = get_formatted_news(api_url, headers, params)

        is_article_exist = is_article_id_exists(article_id)

        if(is_article_exist):
            print(str(article_id) + " Article already exists in the database.")

        if title and content and article_url and not is_article_exist:
            formatted_content = format_content(title, content, prompt)
            source_link = get_source_link(article_url)

            if source_link:
                tweet_content = f"{formatted_content}\n\n{source_link if source_link else 'No source link found.'}"
                print(schedule_tweet(tweet_content))
                update_last_article_id(article_id)
            else:
                print("Source link not found.")
        else:
            print("No new content to process or error fetching data.")
    except Exception as e:
        print("An error occurred:", e)
    finally:
        print("Execution completed.")

if __name__ == "__main__":
    main()
