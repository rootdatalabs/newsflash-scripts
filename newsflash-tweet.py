import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime, timedelta
import pytz
from supabase import create_client, Client
from dotenv import load_dotenv
import os
import socket
import traceback

if "GITHUB_ACTIONS" not in os.environ:
    load_dotenv()

# get env from .env file
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
X_API_KEY = os.getenv("X_API_KEY")
X_KR_API_KEY = os.getenv("X_KR_API_KEY")
OPEN_AI_KEY = os.getenv("OPEN_AI_KEY")
HEADER_TOKEN = os.getenv("HEADER_TOKEN")

# init supabase client
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def get_source_link(article_url):
    print(f"\n=== å¼€å§‹è·å–æºé“¾æ¥ ===")
    print(f"æ–‡ç« URL: {article_url}")
    
    try:
        print("å‘é€HTTPè¯·æ±‚...")
        start_time = time.time()
        response = requests.get(article_url, timeout=30)
        end_time = time.time()
        print(f"è¯·æ±‚å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        response.raise_for_status()
        
        print("è§£æHTMLå†…å®¹...")
        soup = BeautifulSoup(response.text, 'html.parser')
        
        print("æŸ¥æ‰¾æ¥æºé“¾æ¥æ ‡ç­¾...")
        source_link_tag = soup.find('div', class_="rich_text_content mb-4")
        if source_link_tag:
            print("æ‰¾åˆ°å†…å®¹div")
            link_tag = source_link_tag.find('a', string='(æ¥æºé“¾æ¥)')
            if link_tag:
                source_link = link_tag['href']
                print(f"æ‰¾åˆ°æºé“¾æ¥: {source_link}")
                return source_link
            else:
                print("æœªæ‰¾åˆ°(æ¥æºé“¾æ¥)æ ‡ç­¾")
        else:
            print("æœªæ‰¾åˆ°rich_text_content div")
            
    except requests.RequestException as e:
        print(f"è¯·æ±‚å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
    except AttributeError as e:
        print(f"è§£æå¼‚å¸¸: {str(e)}")
        traceback.print_exc()
    except Exception as e:
        print(f"å…¶ä»–å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
        
    print("æœªèƒ½è·å–æºé“¾æ¥")
    return None

def get_formatted_news(api_url, headers, params):
    print(f"\n=== å¼€å§‹è·å–æ–°é—» ===")
    print(f"API URL: {api_url}")
    print(f"è¯·æ±‚å¤´: {headers}")
    print(f"è¯·æ±‚å‚æ•°: {params}")
    
    try:
        # å…ˆæµ‹è¯•åŸŸåè§£æ
        domain = api_url.split("//")[1].split("/")[0]
        print(f"å°è¯•è§£æåŸŸå: {domain}...")
        try:
            ip = socket.gethostbyname(domain)
            print(f"åŸŸåè§£ææˆåŠŸ! IP: {ip}")
        except socket.gaierror as e:
            print(f"åŸŸåè§£æå¤±è´¥: {str(e)}")
            return None, None, None, None
        
        # å‘é€APIè¯·æ±‚
        print("å‘é€POSTè¯·æ±‚...")
        start_time = time.time()
        response = requests.post(api_url, headers=headers, json=params, timeout=30)
        end_time = time.time()
        print(f"è¯·æ±‚å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        # æ£€æŸ¥å“åº”
        if response.status_code == 200:
            print("è§£æå“åº”JSON...")
            try:
                response_json = response.json()
                print(f"å“åº”ç»“æœ: {response_json.get('result')}")
                
                if response_json.get('result') == 1:
                    article = response_json['data']['list'][0]
                    if article:
                        title = article['title']
                        content = article['content']
                        article_url = article['url']
                        article_id = article['id']
                        
                        print(f"æˆåŠŸè·å–æ–°é—»:")
                        print(f"- ID: {article_id}")
                        print(f"- æ ‡é¢˜: {title}")
                        print(f"- å†…å®¹å‰50å­—ç¬¦: {content[:50]}...")
                        print(f"- URL: {article_url}")
                        
                        return title, content, article_url, article_id
                    else:
                        print("æœªæ‰¾åˆ°æ–‡ç« å†…å®¹")
                else:
                    print(f"APIè¿”å›é”™è¯¯ç»“æœ: {response_json}")
            except Exception as e:
                print(f"JSONè§£æé”™è¯¯: {str(e)}")
                print(f"åŸå§‹å“åº”: {response.text[:500]}...")
        else:
            print(f"APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(f"å“åº”å†…å®¹: {response.text[:500]}...")
    
    except requests.exceptions.ConnectionError as e:
        print(f"è¿æ¥é”™è¯¯: {str(e)}")
        traceback.print_exc()
    except requests.exceptions.Timeout as e:
        print(f"è¯·æ±‚è¶…æ—¶: {str(e)}")
    except Exception as e:
        print(f"å…¶ä»–å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
    
    print("æœªèƒ½è·å–æ ¼å¼åŒ–æ–°é—»")
    return None, None, None, None

def format_content(title, content, prompt, prefix="ğŸ’¡èµ„è®¯\n"):
    print(f"\n=== å¼€å§‹æ ¼å¼åŒ–å†…å®¹ ===")
    print(f"æ ‡é¢˜: {title}")
    print(f"å†…å®¹å‰50å­—ç¬¦: {content[:50]}...")
    
    news_content = f"{title} {content}"
    
    try:
        print("è°ƒç”¨OpenRouter API...")
        start_time = time.time()
        
        # åˆ›å»ºheadersï¼Œæ­£ç¡®è®¾ç½®Authorization
        headers = {
            "Authorization": "Bearer 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",
            "Content-Type": "application/json"
        }
        
        # ä½¿ç”¨requestsç›´æ¥è°ƒç”¨APIè€Œä¸æ˜¯OpenAIå®¢æˆ·ç«¯
        api_url = "https://openrouter.ai/api/v1/chat/completions"
        
        # å…ˆæµ‹è¯•åŸŸåè§£æ
        domain = "openrouter.ai"
        print(f"å°è¯•è§£æåŸŸå: {domain}...")
        try:
            ip = socket.gethostbyname(domain)
            print(f"åŸŸåè§£ææˆåŠŸ! IP: {ip}")
        except socket.gaierror as e:
            print(f"åŸŸåè§£æå¤±è´¥: {str(e)}")
            return prefix + "åŸŸåè§£æå¤±è´¥ï¼Œæ— æ³•æ ¼å¼åŒ–å†…å®¹ã€‚"
        
        # å‡†å¤‡è¯·æ±‚æ•°æ®
        payload = {
            "model": "openai/gpt-4o-mini",
            "messages": [
                {"role": "system", "content": prompt},
                {"role": "user", "content": news_content}
            ],
            "temperature": 0.7
        }
        
        # å‘é€è¯·æ±‚
        print(f"å‘é€POSTè¯·æ±‚åˆ°: {api_url}")
        response = requests.post(api_url, headers=headers, json=payload, timeout=30)
        end_time = time.time()
        print(f"APIè°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        # æ£€æŸ¥å“åº”
        if response.status_code == 200:
            response_data = response.json()
            if "choices" in response_data and len(response_data["choices"]) > 0:
                formatted_news = prefix + response_data["choices"][0]["message"]["content"][:240]
                print(f"æ ¼å¼åŒ–ç»“æœ: {formatted_news}")
                return formatted_news
            else:
                print("APIå“åº”ç¼ºå°‘choiceså­—æ®µ")
                print(f"å“åº”å†…å®¹: {response_data}")
        else:
            print(f"APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯å“åº”: {response.text}")
    except Exception as e:
        print(f"æ ¼å¼åŒ–å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
    
    print("ä½¿ç”¨å¤‡ç”¨æ ¼å¼åŒ–å†…å®¹")
    return prefix + "Content formatting failed."

def schedule_tweet(tweet_content, x_api_key="27VgCEflgFqnrJvA", x_name="ChainCatcher", get_twitter_url=False):
    print(f"\n=== å¼€å§‹å‘å¸ƒ {x_name} æ¨æ–‡ ===")
    print(f"æ¨æ–‡å†…å®¹é•¿åº¦: {len(tweet_content)} å­—ç¬¦")
    print(f"æ¨æ–‡å†…å®¹: {tweet_content}")
    
    typefully_draft_public_url = "https://api.typefully.com/drafts-public/"
    
    try:
        # å…ˆæµ‹è¯•åŸŸåè§£æ
        domain = "api.typefully.com"
        print(f"å°è¯•è§£æåŸŸå: {domain}...")
        try:
            ip = socket.gethostbyname(domain)
            print(f"åŸŸåè§£ææˆåŠŸ! IP: {ip}")
        except socket.gaierror as e:
            print(f"åŸŸåè§£æå¤±è´¥: {str(e)}")
            return None
        
        headers = {"X-API-KEY": f"Bearer {x_api_key}", "Content-Type": "application/json"}
        payload = {
            "content": tweet_content,
            "schedule-date": (datetime.now(pytz.timezone('Asia/Shanghai')) + timedelta(seconds=2)).isoformat(),
            "share": True
        }
        
        print(f"è¯·æ±‚å¤´: {headers}")
        print(f"è¯·æ±‚ä½“: {payload}")
        
        print("å‘é€POSTè¯·æ±‚åˆ°Typefully...")
        start_time = time.time()
        response = requests.post("https://api.typefully.com/v1/drafts/", json=payload, headers=headers)
        end_time = time.time()
        print(f"è¯·æ±‚å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"çŠ¶æ€ç : {response.status_code}")
        
        try:
            response_json = response.json()
            print(f"å“åº”JSON: {response_json}")
            
            twitter_url = None
            
            if response.status_code == 200:
                data = response_json
                typefully_id = data.get("id")
                share_url = data.get("share_url")
                
                if share_url:
                    # Split the URL by '/' and get the last part
                    identifier = share_url.split('/')[-1]
                    print(f"è‰ç¨¿åˆ›å»ºæˆåŠŸ! ID: {typefully_id}, æ ‡è¯†ç¬¦: {identifier}")
                    print(f"åˆ†äº«URL: {share_url}")
                    
                    if get_twitter_url:
                        # ç­‰å¾…ä¸€æ®µæ—¶é—´ä»¥ç¡®ä¿è‰ç¨¿å‘å¸ƒ
                        print("ç­‰å¾…60ç§’ä»¥ç¡®ä¿è‰ç¨¿å‘å¸ƒ...")
                        time.sleep(60)
                        
                        # è·å–æœ€è¿‘å‘å¸ƒçš„è‰ç¨¿
                        print(f"æ£€æŸ¥è‰ç¨¿å‘å¸ƒçŠ¶æ€: {typefully_draft_public_url + identifier}")
                        check_response = requests.get(typefully_draft_public_url + identifier, headers=headers)
                        print(f"æ£€æŸ¥å“åº”çŠ¶æ€ç : {check_response.status_code}")
                        
                        if check_response.status_code == 200:
                            check_data = check_response.json()
                            print(f"æ£€æŸ¥å“åº”JSON: {check_data}")
                            
                            twitter_url = check_data.get("thread_head_twitter_url")
                            if twitter_url:
                                print(f"{x_name} æ¨æ–‡å·²æˆåŠŸå‘å¸ƒ! URL: {twitter_url}")
                            else:
                                print("æœªæ‰¾åˆ°Twitter URLï¼Œå¯èƒ½å°šæœªå‘å¸ƒ")
                        else:
                            print(f"æ£€æŸ¥è‰ç¨¿çŠ¶æ€å¤±è´¥: {check_response.text}")
                else:
                    print("å“åº”ä¸­æœªåŒ…å«share_url")
            else:
                print(f"{x_name} æ¨æ–‡å‘å¸ƒå¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response_json}")
                
            return twitter_url
        
        except ValueError as e:
            print(f"JSONè§£æé”™è¯¯: {str(e)}")
            print(f"åŸå§‹å“åº”: {response.text}")
    
    except Exception as e:
        print(f"å‘å¸ƒæ¨æ–‡å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
    
    print(f"{x_name} æ¨æ–‡å‘å¸ƒå¤±è´¥")
    return None

def is_article_id_exists(article_id):
    print(f"\n=== æ£€æŸ¥æ–‡ç« IDæ˜¯å¦å­˜åœ¨ ===")
    print(f"æ–‡ç« ID: {article_id}")
    
    try:
        print("æŸ¥è¯¢æ•°æ®åº“...")
        data = supabase.table("last_article").select("article_id").eq("article_id", article_id).execute()
        exists = len(data.data) > 0
        print(f"æ–‡ç« IDå­˜åœ¨: {exists}")
        return exists
    except Exception as e:
        print(f"æ•°æ®åº“æŸ¥è¯¢å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
        return False

def update_last_article_id(article_id, title=""):
    print(f"\n=== æ›´æ–°æœ€æ–°æ–‡ç« ID ===")
    print(f"æ–‡ç« ID: {article_id}")
    print(f"æ ‡é¢˜: {title}")
    
    try:
        print("æ’å…¥æ•°æ®åº“...")
        result = supabase.table("last_article").insert({"article_id": article_id, "title": title}).execute()
        print(f"æ’å…¥æˆåŠŸ: {result}")
        return True
    except Exception as e:
        print(f"æ•°æ®åº“æ’å…¥å¼‚å¸¸: {str(e)}")
        traceback.print_exc()
        return False

def main():
    """
    Fetches news articles from an API, processes the content, and schedules a tweet.
    
    This function performs the following steps:
    1. Fetches news articles from the specified API endpoint.
    2. Checks if the article already exists in the database.
    3. If the article is new, formats the content and generates a tweet.
    4. Schedules the tweet for posting.
    5. Updates the last article ID in the database.
    """
    print("\n============= è„šæœ¬å¼€å§‹æ‰§è¡Œ =============")
    print(f"å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("\n=== æµ‹è¯•å…³é”®åŸŸåè§£æ ===")
    
    domains = [
        "www.chaincatcher.com",
        "openrouter.ai",
        "api.typefully.com"
    ]
    
    for domain in domains:
        try:
            print(f"å°è¯•è§£æåŸŸå: {domain}...")
            ip = socket.gethostbyname(domain)
            print(f"åŸŸåè§£ææˆåŠŸ! IP: {ip}")
            
            # æµ‹è¯•HTTPè¿æ¥
            protocol = "https"
            print(f"å°è¯•è¿æ¥: {protocol}://{domain}...")
            start_time = time.time()
            response = requests.get(f"{protocol}://{domain}", timeout=10)
            end_time = time.time()
            print(f"è¿æ¥æˆåŠŸ! çŠ¶æ€ç : {response.status_code}, è€—æ—¶: {end_time - start_time:.2f}ç§’")
        except socket.gaierror as e:
            print(f"åŸŸåè§£æå¤±è´¥: {str(e)}")
        except requests.exceptions.ConnectionError as e:
            print(f"è¿æ¥é”™è¯¯: {str(e)}")
        except requests.exceptions.Timeout as e:
            print(f"è¿æ¥è¶…æ—¶: {str(e)}")
        except Exception as e:
            print(f"æµ‹è¯•å¤±è´¥: {str(e)}")
    
    api_url = "https://www.chaincatcher.com/OpenApi/FetchListByType"
    headers = {"token": HEADER_TOKEN}
    params = {"type": 2, "newsFlashType": 1, "page": 1, "limit": 1}
    #prompt = "è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼šè¾“å…¥åŸå§‹æ–‡æœ¬ã€‚é¦–å…ˆï¼Œä»æ–‡æœ¬ä¸­åˆ é™¤ä»»ä½•æåˆ°'ChainCatcheræ¶ˆæ¯'çš„éƒ¨åˆ†ã€‚ç„¶åï¼Œä¾æ®æ ‡é¢˜å†…å®¹å’Œæ­£æ–‡è¡¥å……ä¿¡æ¯ï¼Œå°†æ–‡æœ¬å†…å®¹å‹ç¼©æˆä¸è¶…è¿‡70å­—çš„æ‘˜è¦ï¼Œä¸è¦åŒ…å«htmlæ ‡ç­¾ï¼Œå¹¶ä¿æŒå†…å®¹ç”¨è¯­æ­£å¼ã€æ–°é—»æ ¼è°ƒï¼ŒåŒæ—¶ä¸­ç«‹å’Œå®¢è§‚ã€‚åœ¨å¤„ç†æ—¶ï¼Œè¯·ç¡®ä¿å°†æ‰€æœ‰ä¸åŠ å¯†è´§å¸é¢†åŸŸç›¸å…³çš„å…³é”®è¯å¦‚'æ¯”ç‰¹å¸'å’Œ'ETF'æ ‡è®°ä¸º#æ¯”ç‰¹å¸ã€#æ¯”ç‰¹å¸ã€#ETFã€#BTCã€#ETHã€#SECã€#FTXã€#SBFã€#çˆ†ä»“ã€#ç°åº¦ã€#å¸å®‰ã€#Coinbaseã€#GaryGenslerã€#OKXã€#Solanaã€#ä»¥å¤ªåŠã€#RWAã€#AIã€#Tetherã€#èµµé•¿é¹ã€#CZã€#åŒºå—é“¾ã€#åŠ å¯†è¡Œä¸šã€#è¨å°”ç“¦å¤šã€#ç¾è”å‚¨ã€#å…ƒå®‡å®™ã€#PEOPLEã€#PEPEã€#èèµ„ã€#SEIã€#Cosmosã€#åŠ å¯†èµ„äº§ã€#CPIã€#ä½•ä¸€ã€#DEXã€#CEXã€#SOLã€#OKBã€#BNBã€#é»‘å®¢æ”»å‡»ã€#memeã€#é²å¨å°”ã€#Runesã€#ç¬¦æ–‡ã€#é“­æ–‡ã€#Ordinalsã€#ORDIã€#Web3ã€#æ…¢é›¾ã€#Layer2ã€#å­™å®‡æ™¨ã€#USDTã€#USDCã€#TONã€#æ¸¯è‚¡ã€#é©¬æ–¯å…‹ã€#ç¨³å®šå¸ç­‰ï¼Œå¹¶åœ¨æ¯ä¸ªæ ‡ç­¾å‰åŠ ä¸Šç©ºæ ¼ï¼Œä½¿è¿™äº›æ ‡ç­¾åˆç†åœ°èå…¥åˆ°å¥å­ä¸­ï¼Œä¿æŒä¿¡æ¯æµç•…ä¸”æ˜“äºç†è§£ã€‚"
    #prompt_kr = prompt + "è¯·æ³¨æ„ï¼Œå°†æœ€ç»ˆå†…å®¹å¿…é¡»å…¨éƒ¨ç¿»è¯‘ä¸ºéŸ©æ–‡ï¼Œç›¸å…³å¸¦æœ‰#çš„å…³é”®è¯æ ‡è®°ä¹Ÿå¿…é¡»ç¿»è¯‘æˆéŸ©æ–‡ã€‚ä¸ä¿ç•™åŸæ¥æ€»ç»“çš„ä¸­æ–‡ã€‚æœ€ç»ˆè¾“å‡ºçš„å­—ç¬¦æ•°æ§åˆ¶åœ¨ 100 ä»¥å†…ã€‚"
    prompt = "è¯·å¤„ç†ä»¥ä¸‹æ–‡æœ¬ï¼šè¾“å…¥åŸå§‹æ–‡æœ¬ã€‚é¦–å…ˆï¼Œä»æ–‡æœ¬ä¸­åˆ é™¤ä»»ä½•æåˆ°'ChainCatcheræ¶ˆæ¯'çš„éƒ¨åˆ†ã€‚\n\nã€é‡è¦æ—¶æ•ˆæ€§æŒ‡å¯¼ã€‘\n\n1. è¯·ç‰¹åˆ«æ³¨æ„æ–°é—»ä¸­æ¶‰åŠæ”¿æ²»äººç‰©ã€å…¬å¸é¢†å¯¼äººå’Œå…¶ä»–å…¬ä¼—äººç‰©çš„èŒä½æè¿°å‡†ç¡®æ€§\n\n2. ä¸è¦éšæ„å‡è®¾æˆ–æ”¹å˜åŸæ–‡ä¸­æ”¿æ²»äººç‰©çš„èŒä½å’Œèº«ä»½\n\n3. å¦‚æœä¸ç¡®å®šæŸäººçš„å½“å‰èŒä½æˆ–çŠ¶æ€ï¼Œè¯·ç›´æ¥ä½¿ç”¨åŸæ–‡ä¸­çš„æè¿°ï¼Œæˆ–é‡‡ç”¨æ›´é€šç”¨çš„ç§°è°“ï¼ˆå¦‚'æ”¿æ²»äººç‰©'ã€'ä¼ä¸šå®¶'ç­‰ï¼‰\n\n4. é¿å…ä½¿ç”¨'ç°ä»»'ã€'å‰ä»»'ç­‰æ—¶æ•ˆæ€§è¯è¯­ï¼Œé™¤éåŸæ–‡æ˜ç¡®æåŠ\n\n5. å¯¹äºä»»ä½•æ¶‰åŠå›½é™…å…³ç³»å’Œæ”¿æ²»å˜åŠ¨çš„ä¿¡æ¯ï¼Œä¸¥æ ¼éµå¾ªåŸæ–‡ï¼Œä¸æ·»åŠ è‡ªå·±çš„åˆ¤æ–­\n\nç„¶åï¼Œä¾æ®æ ‡é¢˜å†…å®¹å’Œæ­£æ–‡è¡¥å……ä¿¡æ¯ï¼Œå°†æ–‡æœ¬å†…å®¹å‹ç¼©æˆä¸è¶…è¿‡70å­—çš„æ‘˜è¦ï¼Œä¸è¦åŒ…å«htmlæ ‡ç­¾ï¼Œå¹¶ä¿æŒå†…å®¹ç”¨è¯­æ­£å¼ã€æ–°é—»æ ¼è°ƒï¼ŒåŒæ—¶ä¸­ç«‹å’Œå®¢è§‚ã€‚åœ¨å¤„ç†æ—¶ï¼Œè¯·ç¡®ä¿å°†æ‰€æœ‰ä¸åŠ å¯†è´§å¸é¢†åŸŸç›¸å…³çš„å…³é”®è¯å¦‚'æ¯”ç‰¹å¸'å’Œ'ETF'æ ‡è®°ä¸º#æ¯”ç‰¹å¸ã€#ETFã€#BTCã€#ETHã€#SECã€#FTXã€#SBFã€#çˆ†ä»“ã€#ç°åº¦ã€#å¸å®‰ã€#Coinbaseã€#GaryGenslerã€#OKXã€#Solanaã€#ä»¥å¤ªåŠã€#RWAã€#AIã€#Tetherã€#èµµé•¿é¹ã€#CZã€#åŒºå—é“¾ã€#åŠ å¯†è¡Œä¸šã€#è¨å°”ç“¦å¤šã€#ç¾è”å‚¨ã€#å…ƒå®‡å®™ã€#PEOPLEã€#PEPEã€#èèµ„ã€#SEIã€#Cosmosã€#åŠ å¯†èµ„äº§ã€#CPIã€#ä½•ä¸€ã€#DEXã€#CEXã€#SOLã€#OKBã€#BNBã€#é»‘å®¢æ”»å‡»ã€#memeã€#é²å¨å°”ã€#Runesã€#ç¬¦æ–‡ã€#é“­æ–‡ã€#Ordinalsã€#ORDIã€#Web3ã€#æ…¢é›¾ã€#Layer2ã€#å­™å®‡æ™¨ã€#USDTã€#USDCã€#TONã€#æ¸¯è‚¡ã€#é©¬æ–¯å…‹ã€#ç¨³å®šå¸ç­‰ï¼Œå¹¶åœ¨æ¯ä¸ªæ ‡ç­¾å‰åŠ ä¸Šç©ºæ ¼ï¼Œä½¿è¿™äº›æ ‡ç­¾åˆç†åœ°èå…¥åˆ°å¥å­ä¸­ï¼Œä¿æŒä¿¡æ¯æµç•…ä¸”æ˜“äºç†è§£ã€‚"
    prompt_kr = prompt + "è¯·æ³¨æ„ï¼Œå°†æœ€ç»ˆå†…å®¹å¿…é¡»å…¨éƒ¨ç¿»è¯‘ä¸ºéŸ©æ–‡ï¼Œç›¸å…³å¸¦æœ‰#çš„å…³é”®è¯æ ‡è®°ä¹Ÿå¿…é¡»ç¿»è¯‘æˆéŸ©æ–‡ã€‚ä¸ä¿ç•™åŸæ¥æ€»ç»“çš„ä¸­æ–‡ã€‚æœ€ç»ˆè¾“å‡ºçš„å­—ç¬¦æ•°æ§åˆ¶åœ¨ 100 ä»¥å†…ã€‚åœ¨ç¿»è¯‘è¿‡ç¨‹ä¸­ï¼ŒåŒæ ·éœ€è¦ä¿æŒæ”¿æ²»äººç‰©èŒä½æè¿°çš„å‡†ç¡®æ€§ã€‚"
    try:
        print("\n=== å¼€å§‹ä¸»è¦ä¸šåŠ¡æµç¨‹ ===")
        print(f"HEADER_TOKEN è®¾ç½®çŠ¶æ€: {'å·²è®¾ç½®' if HEADER_TOKEN else 'æœªè®¾ç½®'}")
        
        # è·å–æ–°é—»å†…å®¹
        title, content, article_url, article_id = get_formatted_news(api_url, headers, params)
        
        # æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨
        is_article_exist = is_article_id_exists(article_id) if article_id else True
        
        print(f"\n=== æ–°é—»è·å–ç»“æœ ===")
        print(f"æ–‡ç« ID: {article_id}")
        print(f"æ ‡é¢˜: {title}")
        print(f"å†…å®¹å‰100å­—ç¬¦: {content[:100] if content else None}")
        print(f"æ–‡ç« URL: {article_url}")
        print(f"æ–‡ç« å·²å­˜åœ¨: {is_article_exist}")
        
        if is_article_exist:
            print(f"æ–‡ç« ID {article_id} å·²å­˜åœ¨äºæ•°æ®åº“ä¸­ï¼Œè·³è¿‡å¤„ç†ã€‚")
        
        if title and content and article_url and not is_article_exist:
            # æ ¼å¼åŒ–å†…å®¹
            formatted_content = format_content(title, content, prompt)
            formatted_content_kr = format_content(title, content, prompt_kr, "ğŸ’¡ë‰´ìŠ¤\n")
            
            # è·å–æºé“¾æ¥
            source_link = get_source_link(article_url)
            
            if source_link:
                print("\n=== å‡†å¤‡å‘å¸ƒæ¨æ–‡ ===")
                twitter_url_cn = None
                tweet_content = f"{formatted_content}\n\n{source_link if source_link else 'No source link found.'}"
                
                # å‘å¸ƒä¸­æ–‡æ¨æ–‡
                twitter_url_cn = schedule_tweet(tweet_content)
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´
                print("ç­‰å¾…5ç§’åå‘å¸ƒéŸ©æ–‡æ¨æ–‡...")
                time.sleep(5)
                
                # å‡†å¤‡éŸ©æ–‡æ¨æ–‡å†…å®¹
                if twitter_url_cn:
                    tweet_content_kr = f"{formatted_content_kr}\n\n{twitter_url_cn}"
                else:
                    tweet_content_kr = f"{formatted_content_kr}\n\n{source_link}"
                
                # å‘å¸ƒéŸ©æ–‡æ¨æ–‡
                schedule_tweet(tweet_content_kr, X_KR_API_KEY, "ChainCatcher KR")
                
                # æ›´æ–°æ•°æ®åº“
                update_last_article_id(article_id, title)
                print("æ–°æ–‡ç« å¤„ç†å®Œæˆ")
            else:
                print("æœªæ‰¾åˆ°æºé“¾æ¥ï¼Œæ— æ³•å‘å¸ƒæ¨æ–‡")
        else:
            if not title or not content or not article_url:
                print("APIæœªè¿”å›æœ‰æ•ˆå†…å®¹ï¼Œæ— æ³•å¤„ç†")
            elif is_article_exist:
                print("æ–‡ç« å·²å­˜åœ¨ï¼Œæ— éœ€å¤„ç†")
    except Exception as e:
        print(f"\n=== å‘ç”Ÿé”™è¯¯ ===\n{str(e)}")
        traceback.print_exc()
    finally:
        print("\n============= è„šæœ¬æ‰§è¡Œå®Œæ¯• =============")

if __name__ == "__main__":
    main()
